{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud #installing wordcloud library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wordcloud in c:\\users\\moyka\\appdata\\roaming\\python\\python311\\site-packages (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.24.3)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add parent directory to path to import modules from src\n",
    "rpath = os.path.abspath(r'C:\\Users\\moyka\\OneDrive\\Documents\\GitHub\\week0_starter_network_analysis')\n",
    "if rpath not in sys.path:\n",
    "    sys.path.insert(0, rpath)\n",
    "\n",
    "from src.loader import SlackDataLoader\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns we can get from a slack message<br>\n",
    "\n",
    "message_type, message_content, sender_id, time_sent, message_distribution, time_thread_start, reply_count, reply_user_count, time_thread_end, reply_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a single slack message, we can get <br>\n",
    "\n",
    "1. The message<br>\n",
    "2. Type (message, file, link, etc)<br>\n",
    "3. The sender_id (assigned by slack)<br>\n",
    "4. The time the message was sent<br>\n",
    "5. The team (i don't know what that is now)<br>\n",
    "6. The type of the message (broadcast message, inhouse, just messgae)<br>\n",
    "7. The thread the message generated (from here we can go):<br>\n",
    "    7.1 Text/content of the message<br>\n",
    "    7.2 The thread time of the message<br>\n",
    "    7.3 The thread count (reply count)<br>\n",
    "    7.4 The number of user that reply the message (count of users that participated in the thread)<br>\n",
    "    7.5 The time the last thread message was sent <br>\n",
    "    7.6 The users that participated in the thread (their ids are stored as well)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all json file in all-weeks8-9\n",
    "def slack_parser(path_channel):\n",
    "    \"\"\" parse slack data to extract useful informations from the json file\n",
    "        step of execution\n",
    "        1. Import the required modules\n",
    "        2. read all json file from the provided path\n",
    "        3. combine all json files in the provided path\n",
    "        4. extract all required informations from the slack data\n",
    "        5. convert to dataframe and merge all\n",
    "        6. reset the index and return dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # specify path to get json files\n",
    "    combined = []\n",
    "    for json_file in glob.glob(f\"{path_channel}*.json\"):\n",
    "        with open(json_file, 'r', encoding=\"utf8\") as slack_data:\n",
    "            file_content = json.load(slack_data)\n",
    "            combined.append(file_content)\n",
    "            #combined.append(slack_data)\n",
    "\n",
    "    # loop through all json files and extract required informations\n",
    "    dflist = []\n",
    "    for slack_data in combined:\n",
    "\n",
    "        msg_type, msg_content, sender_id, time_msg, msg_dist, time_thread_st, reply_users, \\\n",
    "        reply_count, reply_users_count, tm_thread_end = [],[],[],[],[],[],[],[],[],[]\n",
    "\n",
    "        for row in slack_data:\n",
    "            if 'bot_id' in row.keys():\n",
    "                continue\n",
    "            else:\n",
    "                msg_type.append(row['type'])\n",
    "                msg_content.append(row['text'])\n",
    "                if 'user_profile' in row.keys(): sender_id.append(row['user_profile']['real_name'])\n",
    "                else: sender_id.append('Not provided')\n",
    "                time_msg.append(row['ts'])\n",
    "                if 'blocks' in row.keys() and len(row['blocks'][0]['elements'][0]['elements']) != 0 :\n",
    "                     msg_dist.append(row['blocks'][0]['elements'][0]['elements'][0]['type'])\n",
    "                else: msg_dist.append('reshared')\n",
    "                if 'thread_ts' in row.keys():\n",
    "                    time_thread_st.append(row['thread_ts'])\n",
    "                else:\n",
    "                    time_thread_st.append(0)\n",
    "                if 'reply_users' in row.keys(): reply_users.append(\",\".join(row['reply_users'])) \n",
    "                else:    reply_users.append(0)\n",
    "                if 'reply_count' in row.keys():\n",
    "                    reply_count.append(row['reply_count'])\n",
    "                    reply_users_count.append(row['reply_users_count'])\n",
    "                    tm_thread_end.append(row['latest_reply'])\n",
    "                else:\n",
    "                    reply_count.append(0)\n",
    "                    reply_users_count.append(0)\n",
    "                    tm_thread_end.append(0)\n",
    "        data = zip(msg_type, msg_content, sender_id, time_msg, msg_dist, time_thread_st,\n",
    "         reply_count, reply_users_count, reply_users, tm_thread_end)\n",
    "        columns = ['msg_type', 'msg_content', 'sender_name', 'msg_sent_time', 'msg_dist_type',\n",
    "         'time_thread_start', 'reply_count', 'reply_users_count', 'reply_users', 'tm_thread_end']\n",
    "\n",
    "        df = pd.DataFrame(data=data, columns=columns)\n",
    "        df = df[df['sender_name'] != 'Not provided']\n",
    "        dflist.append(df)\n",
    "\n",
    "    dfall = pd.concat(dflist, ignore_index=True)\n",
    "    dfall['channel'] = path_channel.split('/')[-1].split('.')[0]        \n",
    "    dfall = dfall.reset_index(drop=True)\n",
    "    \n",
    "    return dfall\n",
    "\n",
    "\n",
    "def parse_slack_reaction(path, channel):\n",
    "    \"\"\"get reactions\"\"\"\n",
    "    dfall_reaction = pd.DataFrame()\n",
    "    combined = []\n",
    "    for json_file in glob.glob(f\"{path}*.json\"):\n",
    "        with open(json_file, 'r') as slack_data:\n",
    "            combined.append(slack_data)\n",
    "\n",
    "    reaction_name, reaction_count, reaction_users, msg, user_id = [], [], [], [], []\n",
    "\n",
    "    for k in combined:\n",
    "        slack_data = json.load(open(k.name, 'r', encoding=\"utf-8\"))\n",
    "        \n",
    "        for i_count, i in enumerate(slack_data):\n",
    "            if 'reactions' in i.keys():\n",
    "                for j in range(len(i['reactions'])):\n",
    "                    msg.append(i['text'])\n",
    "                    user_id.append(i['user'])\n",
    "                    reaction_name.append(i['reactions'][j]['name'])\n",
    "                    reaction_count.append(i['reactions'][j]['count'])\n",
    "                    reaction_users.append(\",\".join(i['reactions'][j]['users']))\n",
    "                \n",
    "    data_reaction = zip(reaction_name, reaction_count, reaction_users, msg, user_id)\n",
    "    columns_reaction = ['reaction_name', 'reaction_count', 'reaction_users_count', 'message', 'user_id']\n",
    "    df_reaction = pd.DataFrame(data=data_reaction, columns=columns_reaction)\n",
    "    df_reaction['channel'] = channel\n",
    "    return df_reaction\n",
    "\n",
    "def get_community_participation(path):\n",
    "    \"\"\" specify path to get json files\"\"\"\n",
    "    combined = []\n",
    "    comm_dict = {}\n",
    "    for json_file in glob.glob(f\"{path}*.json\"):\n",
    "        with open(json_file, 'r') as slack_data:\n",
    "            combined.append(slack_data)\n",
    "    # print(f\"Total json files is {len(combined)}\")\n",
    "    for i in combined:\n",
    "        a = json.load(open(i.name, 'r', encoding='utf-8'))\n",
    "\n",
    "        for msg in a:\n",
    "            if 'replies' in msg.keys():\n",
    "                for i in msg['replies']:\n",
    "                    comm_dict[i['user']] = comm_dict.get(i['user'], 0)+1\n",
    "    return comm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reaction_name</th>\n",
       "      <th>reaction_count</th>\n",
       "      <th>reaction_users_count</th>\n",
       "      <th>message</th>\n",
       "      <th>user_id</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raised_hands</td>\n",
       "      <td>10</td>\n",
       "      <td>U03UL5LSTG9,U03V785NLSU,U03UUR571A5,U03V61VGQG...</td>\n",
       "      <td>Good morning everyone :blush: welcome to week ...</td>\n",
       "      <td>U03TEPYRM2P</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clap</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UUMR26Q1</td>\n",
       "      <td>Good morning everyone :blush: welcome to week ...</td>\n",
       "      <td>U03TEPYRM2P</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raised_hands::skin-tone-3</td>\n",
       "      <td>1</td>\n",
       "      <td>U03U9EJR362</td>\n",
       "      <td>Good morning everyone :blush: welcome to week ...</td>\n",
       "      <td>U03TEPYRM2P</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flushed</td>\n",
       "      <td>6</td>\n",
       "      <td>U03U1FNPEUX,U03UJKJGRAQ,U03U1HAG9TR,U03UFV7HFN...</td>\n",
       "      <td>hi, i just want to confirm that the submission...</td>\n",
       "      <td>U03UD5B7C3X</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eyes</td>\n",
       "      <td>2</td>\n",
       "      <td>U03UG1Z21JP,U03UJKJGRAQ</td>\n",
       "      <td>hi, i just want to confirm that the submission...</td>\n",
       "      <td>U03UD5B7C3X</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>smile</td>\n",
       "      <td>4</td>\n",
       "      <td>U03UUR571A5,U03U9EJR362,U03UD68RQH3,U03V6HMRPGQ</td>\n",
       "      <td>&lt;@U03UUN8M4RX&gt; In answering my question you sa...</td>\n",
       "      <td>U03UJKJGRAQ</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>joy</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UD68RQH3</td>\n",
       "      <td>that's true &lt;@U03UD68RQH3&gt; I will keep  that i...</td>\n",
       "      <td>U03UJKJGRAQ</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>+1</td>\n",
       "      <td>2</td>\n",
       "      <td>U03UJKJGRAQ,U03U1HAG9TR</td>\n",
       "      <td></td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UD68RQH3</td>\n",
       "      <td>If so the difference lies in what your asked a...</td>\n",
       "      <td>U03U1FNPEUX</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03V8LHPDME</td>\n",
       "      <td>```pip install matplotlib==3.2.2```</td>\n",
       "      <td>U03UUR571A5</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03U1FNPEUX</td>\n",
       "      <td>&lt;@U03U1FNPEUX&gt; Thank you</td>\n",
       "      <td>U03UJN29Y4C</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03V6HMRPGQ</td>\n",
       "      <td>I think it is associated with the success of t...</td>\n",
       "      <td>U03V5Q9N516</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>3</td>\n",
       "      <td>U03UD68RQH3,U03UVHCV6KB,U03V6HMRPGQ</td>\n",
       "      <td>it is something that has monetary value and wh...</td>\n",
       "      <td>U03UG4Q7V42</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>2</td>\n",
       "      <td>U03V6HMRPGQ,U03UG4Q7V42</td>\n",
       "      <td>don't confuse it with it's literal meaning, &lt;@...</td>\n",
       "      <td>U03UD68RQH3</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UD68RQH3</td>\n",
       "      <td>so it is a financial term referring to a commo...</td>\n",
       "      <td>U03V6HMRPGQ</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>2</td>\n",
       "      <td>U03V6HMRPGQ,U03UG4Q7V42</td>\n",
       "      <td>You can find more about it here.\\n&lt;https://www...</td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>raised_hands</td>\n",
       "      <td>1</td>\n",
       "      <td>U03V6HMRPGQ</td>\n",
       "      <td>&lt;@U03V6HMRPGQ&gt; yeah</td>\n",
       "      <td>U03UD68RQH3</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>Thank you all for the answers</td>\n",
       "      <td>U03V6HMRPGQ</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>+1</td>\n",
       "      <td>3</td>\n",
       "      <td>U03UG1Z21JP,U03U1HAG9TR,U03U1FNPEUX</td>\n",
       "      <td>Hey &lt;!channel&gt; your RDS postgres databases are...</td>\n",
       "      <td>U03V8LHPDME</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>+1</td>\n",
       "      <td>5</td>\n",
       "      <td>U03UG1Z21JP,U03UD5B7C3X,U03UD68RQH3,U03UHB8CXD...</td>\n",
       "      <td></td>\n",
       "      <td>U03UUN8M4RX</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>+1::skin-tone-3</td>\n",
       "      <td>1</td>\n",
       "      <td>U03U9EJR362</td>\n",
       "      <td></td>\n",
       "      <td>U03UUN8M4RX</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>+1</td>\n",
       "      <td>6</td>\n",
       "      <td>U03UG1Z21JP,U03UD5B7C3X,U03UD68RQH3,U03UHB8CXD...</td>\n",
       "      <td></td>\n",
       "      <td>U03UUN8M4RX</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>+1::skin-tone-3</td>\n",
       "      <td>1</td>\n",
       "      <td>U03U9EJR362</td>\n",
       "      <td></td>\n",
       "      <td>U03UUN8M4RX</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>2</td>\n",
       "      <td>U03UUN8M4RX,U03UH397319</td>\n",
       "      <td></td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>raised_hands</td>\n",
       "      <td>2</td>\n",
       "      <td>U03UJKJGRAQ,U03UG0YHAUT</td>\n",
       "      <td></td>\n",
       "      <td>U03UUN8M4RX</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>smile</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>didn’t see this when I posted the same thing b...</td>\n",
       "      <td>U03UUN8M4RX</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>:pray: &lt;@U03UVHCV6KB&gt;</td>\n",
       "      <td>U03UG0YHAUT</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>4</td>\n",
       "      <td>U03UVHCV6KB,U03UG0YHAUT,U03UHB8CXDY,U03U1HAG9TR</td>\n",
       "      <td>1pm UTC tomorrow please</td>\n",
       "      <td>U03TEPYRM2P</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>raised_hands</td>\n",
       "      <td>3</td>\n",
       "      <td>U03UD68RQH3,U03UHB8CXDY,U03UG1Z21JP</td>\n",
       "      <td>hi &lt;@U03TEPYRM2P&gt;, i know today's tutorial ses...</td>\n",
       "      <td>U03UD5B7C3X</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>&lt;https://github.com/confluentinc/cp-docker-ima...</td>\n",
       "      <td>U03UKL27B0R</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>This is the official docker image of conlfuent...</td>\n",
       "      <td>U03UKL27B0R</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>raised_hands</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>Always there &lt;@U03UVHCV6KB&gt; :pray:,thank you</td>\n",
       "      <td>U03V6HMRPGQ</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>17</td>\n",
       "      <td>U03UG5VFN03,U03UJGP0C68,U03V785NLSU,U03UG0YHAU...</td>\n",
       "      <td>Good morning winners, welcome to week 9 of wee...</td>\n",
       "      <td>U03TEPYRM2P</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pray</td>\n",
       "      <td>7</td>\n",
       "      <td>U03UUS0MZCZ,U03UG0YHAUT,U03U1FNPEUX,U03UVHCV6K...</td>\n",
       "      <td>Good morning winners, welcome to week 9 of wee...</td>\n",
       "      <td>U03TEPYRM2P</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>muscle</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UD68RQH3</td>\n",
       "      <td>Good morning winners, welcome to week 9 of wee...</td>\n",
       "      <td>U03TEPYRM2P</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>raised_hands</td>\n",
       "      <td>1</td>\n",
       "      <td>U03TT5KEYCF</td>\n",
       "      <td>Good morning winners, welcome to week 9 of wee...</td>\n",
       "      <td>U03TEPYRM2P</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>eyes</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UG5VFN03</td>\n",
       "      <td>How could I join the two tables? do they have ...</td>\n",
       "      <td>U03UJGRN5E0</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03U1FNPEUX</td>\n",
       "      <td>but for the driver_location data the unique on...</td>\n",
       "      <td>U03UUR571A5</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UUR571A5</td>\n",
       "      <td>&lt;@U03UUR571A5&gt; Thanks</td>\n",
       "      <td>U03UJGRN5E0</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>Thank you Fish</td>\n",
       "      <td>U03UJN29Y4C</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UG1Z21JP</td>\n",
       "      <td>this is what worked for me\\n```order_df.merge(...</td>\n",
       "      <td>U03UJGRN5E0</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>raised_hands</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>&lt;@U03UG1Z21JP&gt; If you want to split it to an a...</td>\n",
       "      <td>U03UUR571A5</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>&lt;@U03UVHCV6KB&gt; Thank you</td>\n",
       "      <td>U03UG1Z21JP</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UJGP0C68</td>\n",
       "      <td>Yes, I think drivers location shows where the ...</td>\n",
       "      <td>U03UUR571A5</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>raised_hands</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UVHCV6KB</td>\n",
       "      <td>```from geopy import distance\\n\\nstart_coordin...</td>\n",
       "      <td>U03UUR571A5</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>eyes</td>\n",
       "      <td>5</td>\n",
       "      <td>U03UVHCV6KB,U03UG0SFHGT,U03UUR571A5,U03U1HAG9T...</td>\n",
       "      <td>Just an update on the data from Gokada CEO Olu...</td>\n",
       "      <td>U03UUN8M4RX</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>raised_hands</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UD68RQH3</td>\n",
       "      <td>Just an update on the data from Gokada CEO Olu...</td>\n",
       "      <td>U03UUN8M4RX</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>pray</td>\n",
       "      <td>2</td>\n",
       "      <td>U03UG5VFN03,U03U1FNPEUX</td>\n",
       "      <td>Just an update on the data from Gokada CEO Olu...</td>\n",
       "      <td>U03UUN8M4RX</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>raised_hands</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UJGP0C68</td>\n",
       "      <td>sorry to hear that &lt;@U03UJGP0C68&gt;, hope it's g...</td>\n",
       "      <td>U03V6HMRPGQ</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>white_check_mark</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UJGP0C68</td>\n",
       "      <td>&lt;https://causalnex.readthedocs.io/en/latest/02...</td>\n",
       "      <td>U03UJH1EQQL</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>+1</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UJH1EQQL</td>\n",
       "      <td>&lt;@U03UJH1EQQL&gt; thank you very much it's workin...</td>\n",
       "      <td>U03UJGP0C68</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>raised_hands</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UG5VFN03</td>\n",
       "      <td>&lt;@U03UL5LSTG9&gt; &lt;@U03TT5KEYCF&gt; &lt;@U03U4GULU3Y&gt;</td>\n",
       "      <td>U03V785NLSU</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>raised_hands::skin-tone-4</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UG4Q7V42</td>\n",
       "      <td>&lt;@U03UJGP0C68&gt; &lt;@U03UUR571A5&gt; &lt;@U03V785NLSU&gt; p...</td>\n",
       "      <td>U03U93GNNVB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>raised_hands</td>\n",
       "      <td>12</td>\n",
       "      <td>U03UD68RQH3,U03UG32J3PC,U03UJGRN5E0,U03UG0SFHG...</td>\n",
       "      <td>&lt;@U03UJGP0C68&gt; &lt;@U03UUR571A5&gt; &lt;@U03V785NLSU&gt; p...</td>\n",
       "      <td>U03U93GNNVB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>clap</td>\n",
       "      <td>4</td>\n",
       "      <td>U03UVHCV6KB,U03U1FNPEUX,U03UHB8CXDY,U03UAKATQ22</td>\n",
       "      <td>&lt;@U03UJGP0C68&gt; &lt;@U03UUR571A5&gt; &lt;@U03V785NLSU&gt; p...</td>\n",
       "      <td>U03U93GNNVB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>fire</td>\n",
       "      <td>4</td>\n",
       "      <td>U03TT5KEYCF,U03UJN29Y4C,U03T89ACUUW,U03V8LHPDME</td>\n",
       "      <td>&lt;@U03UJGP0C68&gt; &lt;@U03UUR571A5&gt; &lt;@U03V785NLSU&gt; p...</td>\n",
       "      <td>U03U93GNNVB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>dancer</td>\n",
       "      <td>1</td>\n",
       "      <td>U03TT5KEYCF</td>\n",
       "      <td>&lt;@U03UJGP0C68&gt; &lt;@U03UUR571A5&gt; &lt;@U03V785NLSU&gt; p...</td>\n",
       "      <td>U03U93GNNVB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>clap::skin-tone-3</td>\n",
       "      <td>1</td>\n",
       "      <td>U03U9EJR362</td>\n",
       "      <td>&lt;@U03UJGP0C68&gt; &lt;@U03UUR571A5&gt; &lt;@U03V785NLSU&gt; p...</td>\n",
       "      <td>U03U93GNNVB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>+1</td>\n",
       "      <td>1</td>\n",
       "      <td>U03UUMR26Q1</td>\n",
       "      <td>&lt;@U03UJGP0C68&gt; &lt;@U03UUR571A5&gt; &lt;@U03V785NLSU&gt; p...</td>\n",
       "      <td>U03U93GNNVB</td>\n",
       "      <td>channel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                reaction_name  reaction_count  \\\n",
       "0                raised_hands              10   \n",
       "1                        clap               1   \n",
       "2   raised_hands::skin-tone-3               1   \n",
       "3                     flushed               6   \n",
       "4                        eyes               2   \n",
       "5                       smile               4   \n",
       "6                         joy               1   \n",
       "7                          +1               2   \n",
       "8            white_check_mark               1   \n",
       "9            white_check_mark               1   \n",
       "10           white_check_mark               1   \n",
       "11           white_check_mark               1   \n",
       "12           white_check_mark               3   \n",
       "13           white_check_mark               2   \n",
       "14           white_check_mark               1   \n",
       "15           white_check_mark               2   \n",
       "16               raised_hands               1   \n",
       "17           white_check_mark               1   \n",
       "18                         +1               3   \n",
       "19                         +1               5   \n",
       "20            +1::skin-tone-3               1   \n",
       "21                         +1               6   \n",
       "22            +1::skin-tone-3               1   \n",
       "23           white_check_mark               2   \n",
       "24               raised_hands               2   \n",
       "25                      smile               1   \n",
       "26           white_check_mark               1   \n",
       "27           white_check_mark               4   \n",
       "28               raised_hands               3   \n",
       "29           white_check_mark               1   \n",
       "30           white_check_mark               1   \n",
       "31               raised_hands               1   \n",
       "32           white_check_mark              17   \n",
       "33                       pray               7   \n",
       "34                     muscle               1   \n",
       "35               raised_hands               1   \n",
       "36                       eyes               1   \n",
       "37           white_check_mark               1   \n",
       "38           white_check_mark               1   \n",
       "39           white_check_mark               1   \n",
       "40           white_check_mark               1   \n",
       "41               raised_hands               1   \n",
       "42           white_check_mark               1   \n",
       "43           white_check_mark               1   \n",
       "44               raised_hands               1   \n",
       "45                       eyes               5   \n",
       "46               raised_hands               1   \n",
       "47                       pray               2   \n",
       "48               raised_hands               1   \n",
       "49           white_check_mark               1   \n",
       "50                         +1               1   \n",
       "51               raised_hands               1   \n",
       "52  raised_hands::skin-tone-4               1   \n",
       "53               raised_hands              12   \n",
       "54                       clap               4   \n",
       "55                       fire               4   \n",
       "56                     dancer               1   \n",
       "57          clap::skin-tone-3               1   \n",
       "58                         +1               1   \n",
       "\n",
       "                                 reaction_users_count  \\\n",
       "0   U03UL5LSTG9,U03V785NLSU,U03UUR571A5,U03V61VGQG...   \n",
       "1                                         U03UUMR26Q1   \n",
       "2                                         U03U9EJR362   \n",
       "3   U03U1FNPEUX,U03UJKJGRAQ,U03U1HAG9TR,U03UFV7HFN...   \n",
       "4                             U03UG1Z21JP,U03UJKJGRAQ   \n",
       "5     U03UUR571A5,U03U9EJR362,U03UD68RQH3,U03V6HMRPGQ   \n",
       "6                                         U03UD68RQH3   \n",
       "7                             U03UJKJGRAQ,U03U1HAG9TR   \n",
       "8                                         U03UD68RQH3   \n",
       "9                                         U03V8LHPDME   \n",
       "10                                        U03U1FNPEUX   \n",
       "11                                        U03V6HMRPGQ   \n",
       "12                U03UD68RQH3,U03UVHCV6KB,U03V6HMRPGQ   \n",
       "13                            U03V6HMRPGQ,U03UG4Q7V42   \n",
       "14                                        U03UD68RQH3   \n",
       "15                            U03V6HMRPGQ,U03UG4Q7V42   \n",
       "16                                        U03V6HMRPGQ   \n",
       "17                                        U03UVHCV6KB   \n",
       "18                U03UG1Z21JP,U03U1HAG9TR,U03U1FNPEUX   \n",
       "19  U03UG1Z21JP,U03UD5B7C3X,U03UD68RQH3,U03UHB8CXD...   \n",
       "20                                        U03U9EJR362   \n",
       "21  U03UG1Z21JP,U03UD5B7C3X,U03UD68RQH3,U03UHB8CXD...   \n",
       "22                                        U03U9EJR362   \n",
       "23                            U03UUN8M4RX,U03UH397319   \n",
       "24                            U03UJKJGRAQ,U03UG0YHAUT   \n",
       "25                                        U03UVHCV6KB   \n",
       "26                                        U03UVHCV6KB   \n",
       "27    U03UVHCV6KB,U03UG0YHAUT,U03UHB8CXDY,U03U1HAG9TR   \n",
       "28                U03UD68RQH3,U03UHB8CXDY,U03UG1Z21JP   \n",
       "29                                        U03UVHCV6KB   \n",
       "30                                        U03UVHCV6KB   \n",
       "31                                        U03UVHCV6KB   \n",
       "32  U03UG5VFN03,U03UJGP0C68,U03V785NLSU,U03UG0YHAU...   \n",
       "33  U03UUS0MZCZ,U03UG0YHAUT,U03U1FNPEUX,U03UVHCV6K...   \n",
       "34                                        U03UD68RQH3   \n",
       "35                                        U03TT5KEYCF   \n",
       "36                                        U03UG5VFN03   \n",
       "37                                        U03U1FNPEUX   \n",
       "38                                        U03UUR571A5   \n",
       "39                                        U03UVHCV6KB   \n",
       "40                                        U03UG1Z21JP   \n",
       "41                                        U03UVHCV6KB   \n",
       "42                                        U03UVHCV6KB   \n",
       "43                                        U03UJGP0C68   \n",
       "44                                        U03UVHCV6KB   \n",
       "45  U03UVHCV6KB,U03UG0SFHGT,U03UUR571A5,U03U1HAG9T...   \n",
       "46                                        U03UD68RQH3   \n",
       "47                            U03UG5VFN03,U03U1FNPEUX   \n",
       "48                                        U03UJGP0C68   \n",
       "49                                        U03UJGP0C68   \n",
       "50                                        U03UJH1EQQL   \n",
       "51                                        U03UG5VFN03   \n",
       "52                                        U03UG4Q7V42   \n",
       "53  U03UD68RQH3,U03UG32J3PC,U03UJGRN5E0,U03UG0SFHG...   \n",
       "54    U03UVHCV6KB,U03U1FNPEUX,U03UHB8CXDY,U03UAKATQ22   \n",
       "55    U03TT5KEYCF,U03UJN29Y4C,U03T89ACUUW,U03V8LHPDME   \n",
       "56                                        U03TT5KEYCF   \n",
       "57                                        U03U9EJR362   \n",
       "58                                        U03UUMR26Q1   \n",
       "\n",
       "                                              message      user_id  channel  \n",
       "0   Good morning everyone :blush: welcome to week ...  U03TEPYRM2P  channel  \n",
       "1   Good morning everyone :blush: welcome to week ...  U03TEPYRM2P  channel  \n",
       "2   Good morning everyone :blush: welcome to week ...  U03TEPYRM2P  channel  \n",
       "3   hi, i just want to confirm that the submission...  U03UD5B7C3X  channel  \n",
       "4   hi, i just want to confirm that the submission...  U03UD5B7C3X  channel  \n",
       "5   <@U03UUN8M4RX> In answering my question you sa...  U03UJKJGRAQ  channel  \n",
       "6   that's true <@U03UD68RQH3> I will keep  that i...  U03UJKJGRAQ  channel  \n",
       "7                                                      U03UVHCV6KB  channel  \n",
       "8   If so the difference lies in what your asked a...  U03U1FNPEUX  channel  \n",
       "9                 ```pip install matplotlib==3.2.2```  U03UUR571A5  channel  \n",
       "10                           <@U03U1FNPEUX> Thank you  U03UJN29Y4C  channel  \n",
       "11  I think it is associated with the success of t...  U03V5Q9N516  channel  \n",
       "12  it is something that has monetary value and wh...  U03UG4Q7V42  channel  \n",
       "13  don't confuse it with it's literal meaning, <@...  U03UD68RQH3  channel  \n",
       "14  so it is a financial term referring to a commo...  U03V6HMRPGQ  channel  \n",
       "15  You can find more about it here.\\n<https://www...  U03UVHCV6KB  channel  \n",
       "16                                <@U03V6HMRPGQ> yeah  U03UD68RQH3  channel  \n",
       "17                      Thank you all for the answers  U03V6HMRPGQ  channel  \n",
       "18  Hey <!channel> your RDS postgres databases are...  U03V8LHPDME  channel  \n",
       "19                                                     U03UUN8M4RX  channel  \n",
       "20                                                     U03UUN8M4RX  channel  \n",
       "21                                                     U03UUN8M4RX  channel  \n",
       "22                                                     U03UUN8M4RX  channel  \n",
       "23                                                     U03UVHCV6KB  channel  \n",
       "24                                                     U03UUN8M4RX  channel  \n",
       "25  didn’t see this when I posted the same thing b...  U03UUN8M4RX  channel  \n",
       "26                              :pray: <@U03UVHCV6KB>  U03UG0YHAUT  channel  \n",
       "27                           1pm UTC tomorrow please   U03TEPYRM2P  channel  \n",
       "28  hi <@U03TEPYRM2P>, i know today's tutorial ses...  U03UD5B7C3X  channel  \n",
       "29  <https://github.com/confluentinc/cp-docker-ima...  U03UKL27B0R  channel  \n",
       "30  This is the official docker image of conlfuent...  U03UKL27B0R  channel  \n",
       "31       Always there <@U03UVHCV6KB> :pray:,thank you  U03V6HMRPGQ  channel  \n",
       "32  Good morning winners, welcome to week 9 of wee...  U03TEPYRM2P  channel  \n",
       "33  Good morning winners, welcome to week 9 of wee...  U03TEPYRM2P  channel  \n",
       "34  Good morning winners, welcome to week 9 of wee...  U03TEPYRM2P  channel  \n",
       "35  Good morning winners, welcome to week 9 of wee...  U03TEPYRM2P  channel  \n",
       "36  How could I join the two tables? do they have ...  U03UJGRN5E0  channel  \n",
       "37  but for the driver_location data the unique on...  U03UUR571A5  channel  \n",
       "38                              <@U03UUR571A5> Thanks  U03UJGRN5E0  channel  \n",
       "39                                     Thank you Fish  U03UJN29Y4C  channel  \n",
       "40  this is what worked for me\\n```order_df.merge(...  U03UJGRN5E0  channel  \n",
       "41  <@U03UG1Z21JP> If you want to split it to an a...  U03UUR571A5  channel  \n",
       "42                           <@U03UVHCV6KB> Thank you  U03UG1Z21JP  channel  \n",
       "43  Yes, I think drivers location shows where the ...  U03UUR571A5  channel  \n",
       "44  ```from geopy import distance\\n\\nstart_coordin...  U03UUR571A5  channel  \n",
       "45  Just an update on the data from Gokada CEO Olu...  U03UUN8M4RX  channel  \n",
       "46  Just an update on the data from Gokada CEO Olu...  U03UUN8M4RX  channel  \n",
       "47  Just an update on the data from Gokada CEO Olu...  U03UUN8M4RX  channel  \n",
       "48  sorry to hear that <@U03UJGP0C68>, hope it's g...  U03V6HMRPGQ  channel  \n",
       "49  <https://causalnex.readthedocs.io/en/latest/02...  U03UJH1EQQL  channel  \n",
       "50  <@U03UJH1EQQL> thank you very much it's workin...  U03UJGP0C68  channel  \n",
       "51       <@U03UL5LSTG9> <@U03TT5KEYCF> <@U03U4GULU3Y>  U03V785NLSU  channel  \n",
       "52  <@U03UJGP0C68> <@U03UUR571A5> <@U03V785NLSU> p...  U03U93GNNVB  channel  \n",
       "53  <@U03UJGP0C68> <@U03UUR571A5> <@U03V785NLSU> p...  U03U93GNNVB  channel  \n",
       "54  <@U03UJGP0C68> <@U03UUR571A5> <@U03V785NLSU> p...  U03U93GNNVB  channel  \n",
       "55  <@U03UJGP0C68> <@U03UUR571A5> <@U03V785NLSU> p...  U03U93GNNVB  channel  \n",
       "56  <@U03UJGP0C68> <@U03UUR571A5> <@U03V785NLSU> p...  U03U93GNNVB  channel  \n",
       "57  <@U03UJGP0C68> <@U03UUR571A5> <@U03V785NLSU> p...  U03U93GNNVB  channel  \n",
       "58  <@U03UJGP0C68> <@U03UUR571A5> <@U03V785NLSU> p...  U03U93GNNVB  channel  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = slack_parser(r'C:/Users/moyka/OneDrive/Documents/GitHub/allweeks89/')\n",
    "parse_slack_reaction = parse_slack_reaction(r'C:/Users/moyka/OneDrive/Documents/GitHub/allweeks89/', 'channel')\n",
    "parse_slack_reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_2_timestamp(column, data):\n",
    "    \"\"\"convert from unix time to readable timestamp\n",
    "        args: column: columns that needs to be converted to timestamp\n",
    "                data: data that has the specified column\n",
    "    \"\"\"\n",
    "    if column in data.columns.values:\n",
    "        timestamp_ = []\n",
    "        for time_unix in data[column]:\n",
    "            if time_unix == 0:\n",
    "                timestamp_.append(0)\n",
    "            else:\n",
    "                a = datetime.datetime.fromtimestamp(float(time_unix))\n",
    "                timestamp_.append(a.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        return timestamp_\n",
    "    else: \n",
    "        print(f\"{column} not in data\")\n",
    "\n",
    "def get_tagged_users(df):\n",
    "    \"\"\"get all @ in the messages\"\"\"\n",
    "\n",
    "    return df['msg_content'].map(lambda x: re.findall(r'@U\\w+', x))\n",
    "\n",
    "\n",
    "    \n",
    "def map_userid_2_realname(user_profile: dict, comm_dict: dict, plot=False):\n",
    "    \"\"\"\n",
    "    map slack_id to realnames\n",
    "    user_profile: a dictionary that contains users info such as real_names\n",
    "    comm_dict: a dictionary that contains slack_id and total_message sent by that slack_id\n",
    "    \"\"\"\n",
    "    user_dict = {} # to store the id\n",
    "    real_name = [] # to store the real name\n",
    "    ac_comm_dict = {} # to store the mapping\n",
    "    count = 0\n",
    "    # collect all the real names\n",
    "    for i in range(len(user_profile['profile'])):\n",
    "        real_name.append(dict(user_profile['profile'])[i]['real_name'])\n",
    "\n",
    "    # loop the slack ids\n",
    "    for i in user_profile['id']:\n",
    "        user_dict[i] = real_name[count]\n",
    "        count += 1\n",
    "\n",
    "    # to store mapping\n",
    "    for i in comm_dict:\n",
    "        if i in user_dict:\n",
    "            ac_comm_dict[user_dict[i]] = comm_dict[i]\n",
    "\n",
    "    ac_comm_dict = pd.DataFrame(data= zip(ac_comm_dict.keys(), ac_comm_dict.values()),\n",
    "    columns=['LearnerName', '# of Msg sent in Threads']).sort_values(by='# of Msg sent in Threads', ascending=False)\n",
    "    \n",
    "    if plot:\n",
    "        ac_comm_dict.plot.bar(figsize=(15, 7.5), x='LearnerName', y='# of Msg sent in Threads')\n",
    "        plt.title('Student based on Message sent in thread', size=20)\n",
    "        \n",
    "    return ac_comm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_20_user(data, channel='Random'):\n",
    "    \"\"\"get user with the highest number of message sent to any channel\"\"\"\n",
    "\n",
    "    data['sender_name'].value_counts()[:20].plot.bar(figsize=(15, 7.5))\n",
    "    plt.title(f'Top 20 Message Senders in #{channel} channels', size=15, fontweight='bold')\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=14);\n",
    "    plt.xticks(size=12); plt.yticks(size=12);\n",
    "    plt.show()\n",
    "\n",
    "    data['sender_name'].value_counts()[-10:].plot.bar(figsize=(15, 7.5))\n",
    "    plt.title(f'Bottom 10 Message Senders in #{channel} channels', size=15, fontweight='bold')\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=14);\n",
    "    plt.xticks(size=12); plt.yticks(size=12);\n",
    "    plt.show()\n",
    "\n",
    "def draw_avg_reply_count(data, channel='Random'):\n",
    "    \"\"\"who commands many reply?\"\"\"\n",
    "\n",
    "    data.groupby('sender_name')['reply_count'].mean().sort_values(ascending=False)[:20]\\\n",
    "        .plot(kind='bar', figsize=(15,7.5));\n",
    "    plt.title(f'Average Number of reply count per Sender in #{channel}', size=20, fontweight='bold')\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=18);\n",
    "    plt.xticks(size=14); plt.yticks(size=14);\n",
    "    plt.show()\n",
    "\n",
    "def draw_avg_reply_users_count(data, channel='Random'):\n",
    "    \"\"\"who commands many user reply?\"\"\"\n",
    "\n",
    "    data.groupby('sender_name')['reply_users_count'].mean().sort_values(ascending=False)[:20].plot(kind='bar',\n",
    "     figsize=(15,7.5));\n",
    "    plt.title(f'Average Number of reply user count per Sender in #{channel}', size=20, fontweight='bold')\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=18);\n",
    "    plt.xticks(size=14); plt.yticks(size=14);\n",
    "    plt.show()\n",
    "\n",
    "def draw_wordcloud(msg_content, week):    \n",
    "    # word cloud visualization\n",
    "    allWords = ' '.join([twts for twts in msg_content])\n",
    "    wordCloud = WordCloud(background_color='#975429', width=500, height=300, random_state=21, max_words=500, mode='RGBA',\n",
    "                            max_font_size=140, stopwords=stopwords.words('english')).generate(allWords)\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    plt.imshow(wordCloud, interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.title(f'WordCloud for {week}', size=30)\n",
    "    plt.show()\n",
    "\n",
    "def draw_user_reaction(data, channel='General'):\n",
    "    data.groupby('sender_name')[['reply_count', 'reply_users_count']].sum()\\\n",
    "        .sort_values(by='reply_count',ascending=False)[:10].plot(kind='bar', figsize=(15, 7.5))\n",
    "    plt.title(f'User with the most reaction in #{channel}', size=25);\n",
    "    plt.xlabel(\"Sender Name\", size=18); plt.ylabel(\"Frequency\", size=18);\n",
    "    plt.xticks(size=14); plt.yticks(size=14);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m slack_parser(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/moyka/OneDrive/Documents/GitHub/all-week9/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df[:\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m      3\u001b[0m df_reaction \u001b[38;5;241m=\u001b[39m parse_slack_reaction(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/moyka/OneDrive/Documents/GitHub/all-week9/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[39], line 26\u001b[0m, in \u001b[0;36mslack_parser\u001b[1;34m(path_channel)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m slack_data \u001b[38;5;129;01min\u001b[39;00m combined:\n\u001b[0;32m     23\u001b[0m     msg_type, msg_content, sender_id, time_msg, msg_dist, time_thread_st, reply_users, \\\n\u001b[0;32m     24\u001b[0m     reply_count, reply_users_count, tm_thread_end \u001b[38;5;241m=\u001b[39m [],[],[],[],[],[],[],[],[],[]\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m slack_data:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbot_id\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m row\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insight Extraction\n",
    "\n",
    "Below are some useful questions to answer. Feel free to explore to answer other interesting questions that may be of help to get insight about student's behaviour, need, and future performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which user has the highest number of reply counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reply counts per user per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the time range of the day that most messages are sent?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what kind of messages are replied faster than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between # of messages and # of reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify messages into different categories such as questions, answers, comments, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which users got the most reactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model topics mentioned in the channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the topics that got the most reactions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harder questions to look into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on messages, reactions, references shared, and other relevant data such as classification of questions into techical question, comment, answer, aorder stu the python, statistics, and sql skill level of a user?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
